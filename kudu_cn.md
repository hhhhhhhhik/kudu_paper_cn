# Kudu:一种面向快速分析的快速数据存储引擎

## 摘要
&emsp;&emsp;Kudu是一款同时支持低延迟随机访问和高效数据分析两种模式的开源结构化存储引擎。Kudu以水平划分的方式将数据进行划分，每个数据片都有副本，并使用raft协议保证数据一致性，提供较低的数据恢复时间和尾延迟。Kudu的设计可无缝搭配Hadoop生态系统，提供对Cloudera Impala，Apache Spark和MapReduce等工具和编程模型的广泛支持。

## 1. 介绍
&emsp;&emsp;最近几年，各大企业产生和抓取的数据成爆炸性的增长，促进了低成本，大规模处理海量数据的相关开源技术蓬勃发展。这其中，Hadoop生态圈成为了“大数据”圈内关注的焦点，而传统开源数据库系统则因为无法提供如此大规模的集群式处理而渐渐落后。

&emsp;&emsp;通常，存储在Hadoop系统内的结构化数据有以下俩种方式：对于静态数据集，通常直接以二进制数据方式直接存储在HDFS上，比如Apache Avro和Apache Parquet。但是，无论是HDFS还是以上这些存储格式，都无法提供数据在单行级别的更新和数据高效的随机访问。而对于可变数据集，通常存储在Apache HBase，Apache Cassandra这类的半结构化存储引擎之上。这样的系统，可提供低延迟的行级的数据读取和写入，但是在处理类似基于SQL分析和机器学习的应用时，往往在顺序读取的吞吐量上远落后于以静态文件存储的方式。

&emsp;&emsp;拥有较强分析性能的HDFS存储静态数据集和拥有低延迟行级随机访问能力的HBase，Cassandra之间的区别和差距，造成了在同一个应用中，开发人员需要设计开发复杂的架构来同时处理这两类问题。特别对于很多Cloudera的用户来说，他们已经设计开发出来这样一套系统，可以通过接入流式数据，集成到HBase中进行实时更新，后续通过一系列的定时作业将这些HBase中的数据表数据导出成Parquet格式用于后续的分析。这样的架构有着以下几方面的不足：

&emsp;&emsp;*1. 应用层必须通过复杂的代码对数据流和两个系统之间的数据同步进行管理。*

&emsp;&emsp;*2. 运维人员需要维护和管理一致的数据备份，安全策略，并监控多个不同的系统的状态。*

&emsp;&emsp;*3. 这样的架构必然会导致数据写入到HBase“中转区域”和数据能够被分析之间的巨大的时间延迟。*

&emsp;&emsp;*4. 实际环境中，系统通常需要处理迟来的数据，过往记录的修改和基于某些策略的数据删除，而这些数据已经被导出成为不可更改的数据存储根式。为了完成这些操作，会造成大量的数据重写，分区交换甚至人工干预。*

&emsp;&emsp;Kudu是一种新的存储系统，它设计并实现来用于提供类似于HDFS的存储系统的高吞吐的顺序访问效率，同时又能提供类似于HBase和Cassandra这类系统低延迟的随机访问能力。尽管这些系统在特定的场景下仍然拥有自己的优势，但Kudu提供了一种“折中”的方式，能显著的简化一些常用系统的开发。另外，Kudu提供简单的行级别的API，包括插入，更新和删除，同时提供接近Parquet（一种被广泛使用的静态列式存储格式）的扫描吞吐性能。

&emsp;&emsp;本文将主要介绍Kudu的体系架构。第二章主要从用户视角介绍系统的数据模型，APIs和一些操作视角的结构。第三章主要介绍Kudu的架构，包括如何在多个节点之间进行数据划分和复制，如何在错误情况下进行数据恢复，如何进行常规的数据操作。第四章主要介绍Kudu为了达到同时保证快速随机访问和高效分析性能，是如何在磁盘上组织数据存储的。第五章主要讨论Kudu和其它Hadoop生态组件的集成。第六章主要提供在综合场景下初步的性能指标结果。

## 2. Kudu概览
### 2.1 表和表结构
&emsp;&emsp;从用户的宏观视角来看，Kudu是一个用来存储表格数据的结构化存储系统。一个Kudu集群可以存储任意多数量的数据表格，这些数据表格都有着有限多数量的列，并且有着定义好的数据。每一个这样的列都包含名称，类型（比如INT32或者STRING）和是否可以为空的选项。这些列的某些有序子集或组成该表格的*主键(primary key)*。主键会保证唯一约束（每一行在同一时间内至多有一个给定的主键元组），并且是对高效的行级别的数据更新与删除的天然索引。对于用户而言，这样的数据结构跟关系型数据库比较相近，但和其它分布式存储系统如Cassandra，MongoDB，Riak，BigTable等有着明显不同。

&emsp;&emsp;与关系数据库一样，用户必须在创建表格table的时候指定对应的模式schema。如果尝试去插入一列没有定义的数据列数据，或者数据违反了主键的唯一约束，都会导致相应的错误。用户需要通过显式的执行*alter table*的命令完成添加和删除列的操作，注意组成主键的列不能被删除。

&emsp;&emsp;出于以下两个因素的考虑，我们最终决定需要显式的指定列类型而不是像NoSQL哲学的“一切皆字节“：

&emsp;&emsp;*1. 我们可以利用显式的列类型针对不同的类型的列数据进行不同的列编码，比如对于整型数据的bit-packing。*

&emsp;&emsp;*2. 我们可以利用显示的列类型组成类SQL的元数据，以便其它被广泛使用的BI和数据探索工具直接使用。*

&emsp;&emsp;和大多数关系数据库不同的是，Kudu当下并不提供二级索引和除主键之外的其它唯一约束。目前，Kudu需要每一个表格table都有定义好的主键，尽管我们在后续版本中会实现代理键的自动生成。

### 2.2 写操作
&emsp;&emsp;在创建完表格table之后，用户可以通过**Insert，Update，Delete**的API来对表格进行数据操作。在各种场景下，用户都必须完整的指定一个主键-基于谓词的删除与更新只能通过更上层的访问机制进行控制（参见第五章）。

&emsp;&emsp;Kudu目前提供C++和Java的API，对于Python提供实验性的支持。通过这些API，可以在需要大批量进行数据操作（比如数据加载和大批量更新）的时候，通过精细的控制批量以及异步的错误处理的降低频繁通信的代价。目前，Kudu并不提供任何多行事务的API：每个变更操作原则上以单独的事务进行执行，尽管也会自动和其他变更操作一起组合，以批量的方式提高性能。对于一行数据的增删改操作在其所有列上都是一个原子操作。

### 2.3 读操作

&emsp;&emsp;对于表格数据的检索的，Kudu只提供**扫描Scan**操作。对于一次扫描，用户可以添加任意数量的谓词过滤条件。目前，我们仅提供两种类型的谓词条件：某一列和一个常量值的比较，主键组合的范围。这些谓词条件将在客户端API和服务端解析，从而高效的剔除无用的数据，降低磁盘和网络的数据传输。

&emsp;&emsp;除了应用谓词条件，用户还可以对扫描指定投影。投影包含了需要被检索到列的一个子集。由于Kudu磁盘采用列式的存储方式，基本上对于大部分场景，选择这样一个列子集都可以有效的提高性能。

### 2.4 其它API
&emsp;&emsp;除了上面描述的这些基于数据路径的API，Kudu还提供了很多有用的功能点。特别是Hadoop生态系统得益于对数据分布方式的调度，性能提升明显。Kudu同样也提供API去帮助调用者决定节点到数据分布区间的映射，从而帮助分布式计算框架比如Spark，MapReduce和Impala去优化调度方式。

### 2.5 一致性模型
&emsp;&emsp;Kudu在客户端提供两种一致性模式。默认的一致性模式是快照一致。一个扫描会保证生成一个不会出现冲突关系的快照。通过这种方式就保证在一个客户端内读你所写read-your-writes的一致性。

&emsp;&emsp;默认情况下，Kudu并不提供*外部一致性external consistency*。这就是说，如果一个客户端执行了一个写操作，然后通过外部的一些机制（比如消息总线）与另外客户端进行通信，而另外的客户端也在执行写操作，这两次写操作的因果一致性无法被捕获到。一个第三方的读者可能会看到一个包含第二次写而不包含第一次写的数据快照。

&emsp;&emsp;基于我们对于一些类似于HBase这样不提供外部一致性的系统的支持经验，这足以用于许多场景。即使用户需要更强的一致性保证，Kudu提供一个基于客户端之间时间戳人工传播的选项：在进行一次写请求后，用户会向客户端库申请一个时间戳令牌，这个令牌可以通过外部的管道传播到另外的客户端，也会传递到Kudu的API。从而保证跨客户端之间写入的因果关系。

&emsp;&emsp;如果令牌传播太过于复杂，Kudu同样提供类似Spanner的提交-等待commit-wait选项。提交-等待被启用的情况下，执行完一次写操作后，客户端会延迟一段时间去确认所有后续的写操作都是因果关系有序的。在缺少专业的时钟硬件的情况下，这样会带来写入显著的延迟（NTP默认配置下100-1000毫秒），所以我们预料到，只会有极少的用户会利用到这个选项。我们同样也注意到，在Spanner发表之后，有些数据存储系统开始利用real-time时钟的优势。鉴于此，可以预见到几年之后，云提供商将会以差异化的方式提供严格的全球时间同步服务。

&emsp;&emsp;操作时间戳的分配是基于一种被称为*HybridTime*的时钟算法实现，具体原理可参考相应的引文。

### 2.6 时间戳
&emsp;&emsp;尽管Kudu在内部使用时间戳实现了并发控制，但Kudu并不提供用户在写入操作的时候设置时间戳。这是与其它系统如Cassandra和HBase不同的地方，在这两个系统中，一个单元的时间戳被看作数据模型中最重要的部分之一。以我们对于这些系统用户的支持经验来看，高级用户能合理的利用时间戳维度，但大部分用户会对这种数据模型感到迷惑，还会导致一些使用错误，尤其是追溯式插入删除语义。

&emsp;&emsp;当然，我们还是会允许用户进行指定时间戳的读操作。这使得用户可以去执行过去某个时间点的查询，同时确保不同的分布式任务来组成的一个“查询”（如在Spark或者Impala）读的是一致的快照。

## 3. 架构
### 3.1 集群角色
### 3.2 数据划分
### 3.3 副本机制
#### 3.3.1 配置改变
### 3.4 Kudu Master节点
#### 3.4.1 元信息管理
#### 3.4.2 集群协调
#### 3.4.3 tablet目录

## 4. Tablet存储
### 4.1 总括
### 4.2 RowSets
### 4.3 MemRowSet实现
### 4.4 DiskRowSet实现
### 4.5 增量Flushes
### 4.6 插入流程
### 4.7 读取流程
### 4.8 延迟物化
### 4.9 增量合并
### 4.10 RowSet合并
### 4.11 维护调度

## 5. Hadoop集成
### 5.1 MapReduce和Spark
&emsp;&emsp;Kudu构建在Hadoop生态圈之上，我们已经优先完成了部分与其它Hadoop组件的核心集成的功能。我们特别提供了针MapReduce作业对Kudu表格数据的输入和输出的绑定。这些绑定同样可以轻松用于Spark。一个轻量级的耦合层可以将Kudu的表格与Spark的上层比如DataFrames和Spark SQL表格绑定在一起。

&emsp;&emsp;这些绑定提供一下关键特性的原生支持：

* **数据分布** - 在内部，输入格式通过向Kudu Master进程请求获取到当前每个表分片所在的具体位置，这样做有利对本地数据处理做优化。

* **列式投影** - 输入格式通过简单的API提供用户选择他们的查询作业所需要的列，这样可以最大化的减少IO的传输。

* **谓词下推** - 输入格式提供简单的API让用户指定谓词条件，这些条件在真正的行数据返回之前，在服务端进行评估计算，这种谓词下推的方式提升了性能，同时可以很轻易的被上层接口比如SparkSQL所使用到。


### 5.2 Impala
&emsp;&emsp;Kudu同样也被深度集成Cloudera Impala中。事实上，Kudu本身并不提供命令行和SQL解析器，支持SQL操作的唯一途径是通过与Impala的集成。Impala的集成包括以下几个关键特性：

* **数据分布** - Impala的查询计划器使用Kudu的Java API的侦测表分片的位置信息，并将后台查询任务的处理进程放在与数据存储相同的节点。对于大部分常规的查询，并不存在Kudu到Impala之间网络的数据传输。我们目前也在调研更进一步的优化方法，比如基于共享内存，使得数据的传输更加高效。

* **谓词下推支持** - Impala的查询计划器经过了修改，目前已经可以识别出可下推至Kudu的谓词条件。在很多场景下，将谓词条件下推会带来IO明显的降低，因为Kudu可以保证在谓词条件过滤完成之后才对相应列数据进行延迟的物化。

* **DDL扩展** - Impala的DDL语句比如**CREATE TABLE**已经扩展支持指定Kudu的分区模式，副本因子和主键定义。

* **DML扩展** - 因为Kudu是Hadoop生态圈中第一种用于分析的可变数据存储引擎，Impala之前并没有实现的DML操作比如**UPDATE**和**DELETE**语句已经可以支持Kudu上的表格。

&emsp;&emsp;得益于Impala更现代的架构，在一个查询中跨多种异构数据存储组件完成数据的传输关联变为现实。比如，一个存储在HDFS上的文本日志文件可以和一个存储在Kudu上多维度的表格进行关联查询。


## 6. 性能评价
### 6.1 对比Parquet
### 6.2 对比Phoenix
### 6.3 随机访问性能

## 7. 总结

## 8. 参考文献
